{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data \n",
    "\n",
    "## Chosen Area\n",
    "\n",
    "For this case study I chose to look at the map of my favorite city in the world, **Shenzhen, China**.\n",
    "\n",
    "Open Street Map data is available at [openstreetmap.org](https://www.openstreetmap.org)\n",
    "\n",
    "The map for Shenzhen was downloaded from [mapzen.com](https://mapzen.com/data/metro-extracts/metro/shenzhen_china/)\n",
    "\n",
    "In this project I will looking through the OpenStreetMap data for Shenzhen to investigate the data, and check to see if there are any inaccuracies or inconsistencies which could be improved upon.\n",
    "\n",
    "## Problems Encountered in the Map\n",
    "\n",
    "- Mix of engish and chinese language. Sometimes the entries include both English and Chinese and sometimes only English.\n",
    "\n",
    "- Road names with inconsitent endings, for example, \"Street\", \"street\", \"St.\", \"St\". \n",
    "\n",
    "- Suspicious postal codes. Chinese postal codes are 6 digits long and contain all numbers. Additionally, the zip codes for Shenzhen begin with 518, like 518000. There were a significant number of postal codes in the map which did not follow this pattern, such as \"DD109 754\" and \"DD124 1957\". I have a suspicion of what these are but some further querying later on in the report should help to clarify what the problem is.\n",
    "\n",
    "### Inconsistent Street Names\n",
    "\n",
    "In order to rectify the problem of having inconsistent street names, I first used following functions from the audit.py script to identify what types of street names existed in the map:\n",
    "\n",
    "```\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "```\n",
    "Then I used the following update_name function to programmatically update the abbreviated street names with the correct names.\n",
    "```\n",
    "def update_name(name, mapping):\n",
    "    words = name.split()\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in mapping:\n",
    "            words[i] = mapping[words[i]]\n",
    "    name = \" \".join(words)\n",
    "    return name\n",
    "```\n",
    "Next I checked to see if the names were correctly updated, here are some of the results:\n",
    "- Hai yue Rd => Hai yue Road\n",
    "- 北环大道 North Ring Ave => 北环大道 North Ring Avenue\n",
    "- 坂雪岗大道 Bǎnxuě Gǎng Av => 坂雪岗大道 Bǎnxuě Gǎng Avenue\n",
    "- 南山大道 Nanshan Dadao => 南山大道 Nanshan DaDao\n",
    "\n",
    "### Sorting by zip code and city\n",
    "```\n",
    "sqlite> SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags \n",
    "   ...> UNION ALL SELECT * FROM ways_tags) tags WHERE tags.key='postcode'\n",
    "   ...> GROUP BY tags.value ORDER BY count DESC LIMIT 10;\n",
    "```\n",
    "|Postal Code|count|\n",
    "|-----|-----|\n",
    "|DD109 754|29|\n",
    "|518000|11|\n",
    "|DD117137|7|\n",
    "|518048|5|\n",
    "|DD1241957|5|\n",
    "|00852|4|\n",
    "|518038|4|\n",
    "|518067|4|\n",
    "|518040|3|\n",
    "|518053|3|\n",
    "  \n",
    "Many of the zip codes are these strange values which begin with DD. Next I will sort by city and see if there is anything strange there which might shed some light on the zip code situation.\n",
    "```\n",
    "SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) tags \n",
    "WHERE tags.key='city' GROUP BY tags.value ORDER BY count DESC LIMIT 10;\n",
    "```\n",
    "|City|count|\n",
    "|-----|-----|\n",
    "|\"香港 Hong Kong\"|334|\n",
    "|\"Sai Kung\"|52|\n",
    "|\"广东省深圳市\"|50|\n",
    "|\"深圳\"|43|\n",
    "|\"Ta Kwu Ling\"|41|\n",
    "|Shenzhen|37|\n",
    "|\"元朗 Yuen Long\"|34|\n",
    "|\"Kam Tin\"|29|\n",
    "|\"深圳市 Shenzhen\"|25|\n",
    "|\"Shap Pat Heung\"|18|\n",
    "\n",
    "This query has highlighted two additional problems with the data.\n",
    "- There is data from both Shenzhen and Hong Kong. I guess this is due to the fact that the map boundary was drawn as a rectangle and since the two cities are so close to eachother it was bound to capture some or Hong Kong.\n",
    "- There are many different spellings of Shenzhen. \"广东省深圳市\" translates to Guangdong Province, Shenzhen City. \"深圳\" are the characters for Shenzhen. \"深圳市 Shenzhen\", contains both the english and chinese spellings of the city name.\n",
    "Further data wrangling could be done to remove the data from Hong Kong and to programmatically update the city names to a more cnosistent format as I previously did with the street names.\n",
    "\n",
    "## Overview of the data\n",
    "\n",
    "(I chose not to make a smaller sample of the data because the original file size was relatively small)\n",
    "\n",
    "|File|Size|\n",
    "|-----|-----|\n",
    "|Shenzhen_china.osm|126.7 MB|\n",
    "|nodes.csv|49.5 MB|\n",
    "|nodes_tags.csv|1.5 MB|\n",
    "|ways.csv|3.8 MB|\n",
    "|ways_nodes.csv|17.1 MB|\n",
    "|ways_tags.csv|5.5 MB|\n",
    "\n",
    "### Number of Nodes\n",
    "```\n",
    "sqlite> SELECT COUNT(*) FROM nodes;\n",
    "```\n",
    "601991\n",
    "\n",
    "### Number of Ways\n",
    "```\n",
    "sqlite> SELECT COUNT(*) FROM ways;\n",
    "```\n",
    "64942\n",
    "\n",
    "### Number of Unique Users\n",
    "```\n",
    "sqlite> SELECT COUNT(DISTINCT(m.uid))          \n",
    "   ...> FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) m;\n",
    "```\n",
    "642\n",
    "\n",
    "## Additional Queries\n",
    "\n",
    "### Top 10 amenities\n",
    "```\n",
    "SELECT value, COUNT(*) as num FROM nodes_tags \n",
    "WHERE key=‘amenity' \n",
    "GROUP BY value \n",
    "ORDER BY num DESC \n",
    "LIMIT 10;\n",
    "```\n",
    "|Amenity|Count|\n",
    "|-----|-----|\n",
    "|toilets|324|\n",
    "|post_box|166|\n",
    "|shelter|163|\n",
    "|restaurant|154|\n",
    "|parking|109|\n",
    "|bank|101|\n",
    "|bus_station|101|\n",
    "|bicycle_parking|86|\n",
    "|fuel|83|\n",
    "|fast_food|64|\n",
    "\n",
    "### Top 10 Cuisines\n",
    "```\n",
    "SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags \n",
    "JOIN (SELECT DISTINCT(id) FROM nodes_tags \n",
    "WHERE value='restaurant') r ON nodes_tags.id=r.id \n",
    "WHERE nodes_tags.key=‘cuisine' \n",
    "GROUP BY nodes_tags.value \n",
    "ORDER BY num DESC \n",
    "LIMIT 10;\n",
    "```\n",
    "|Cuisine|Count|\n",
    "|-----|-----|\n",
    "|chinese|32|\n",
    "|local|4|\n",
    "|burger|3|\n",
    "|cantonese|3|\n",
    "|korean|3|\n",
    "|regional|3|\n",
    "|vegetarian|3\n",
    "|ice_cream|2|\n",
    "|noodle|2|\n",
    "|pizza|2|\n",
    "- Who would have thought Chinese would be the top cuisine?\n",
    "\n",
    "\n",
    "### Top 5 Fast Food Restaurants\n",
    "```\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value = 'fast_food') ff\n",
    "ON nodes_tags.id=ff.id\n",
    "WHERE nodes_tags.key='name'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "|Restaurant|Count|\n",
    "|-----|-----|\n",
    "|\"McDonald's\"|19|\n",
    "|KFC|9|\n",
    "|\"大家樂 Café de Coral\"|3|\n",
    "|\"Burger King\"|2|\n",
    "|McDonalds|2|\n",
    "\n",
    "- It is not surprising that McDonalds wold be the top fast food restuarant in any city in the world, but it turns out that there are multiple spellings of McDonalds in this map. \n",
    "- I now want to check how many total McDonalds restaurants there are in the city, including variations in spelling.\n",
    "```\n",
    "SELECT nodes_tags.value, COUNT(*) FROM nodes_tags\n",
    "WHERE value LIKE '%McDonald%';\n",
    "```\n",
    "**\"McDonald's\",36**\n",
    "\n",
    "I am also curious how many Starbucks there are.\n",
    "```\n",
    "SELECT nodes_tags.value, COUNT(*) FROM nodes_tags\n",
    "WHERE value LIKE '%Starbucks%';\n",
    "```\n",
    "**\"Starbucks Coffee”,10**\n",
    "\n",
    "### Top 3 Religions\n",
    "```\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') rel\n",
    "ON nodes_tags.id=rel.id\n",
    "WHERE nodes_tags.key='religion'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 3;\n",
    "```\n",
    "|Religion|Count|\n",
    "|-----|-----|\n",
    "|christian|11|\n",
    "|buddhist|9|\n",
    "|taoist|8|\n",
    "\n",
    "## Other Ideas About the Dataset\n",
    "\n",
    "In order to get deeper in to the data I would need to do some additional data wrangling, including:\n",
    "- Translating the entries in the dataset into a common language. Right now there are entries in English, Chinese characters, and Chinese Pinyin, which makes it difficult to get clear answers from any queries on the data. This of course would be a very difficult and time consuming process and would require help from someone with stronger chinese language abilities.\n",
    "- Separating the data from Hong Kong and Shenzhen so that each city can be investigated separately and a clearer picture can be painted for each city individually. This could be done by identifiying which zip codes are from Hong Kong and eliminating all entries in the dataset associated with those zip codes.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "It is obvious that there were several problems with the portion of the map chosen for this project. The number of nodes and ways was significantly smaller than other US cities with smaller populations than Shenzhen meaning that there are fewer contributions to OpenStreetMap in Shenzhen. There were also many inconsistencies present in the form of language, abbreviations/misspellings, and entries which were actually from Hong Kong. Still, with the present data, in the condition that it was provided in, there was enough to learn some interesting patterns and it provided me with a great opportunity to practice wrangling and querying data about my favorite city in the world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
